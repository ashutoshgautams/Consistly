#!/bin/bash
set -e

echo "ğŸš€ Starting Consistly on Railway..."

# Start Ollama in background
echo "ğŸ¤– Starting Ollama..."
ollama serve &

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama..."
for i in $(seq 1 30); do
    if curl -s http://localhost:11434/api/version > /dev/null 2>&1; then
        echo "âœ… Ollama is ready!"
        break
    fi
    echo "â³ Attempt $i/30..."
    sleep 2
done

# Download model
echo "ğŸ“¥ Downloading AI model..."
if ! ollama list | grep -q "llama3.1:8b"; then
    echo "ğŸ“¥ First-time setup: downloading model..."
    ollama pull llama3.1:8b
    echo "âœ… Model downloaded!"
else
    echo "âœ… Model already available!"
fi

# Start the web server
echo "ğŸŒ Starting Consistly web server on port $PORT..."
exec uvicorn main:app --host 0.0.0.0 --port $PORT --log-level info
